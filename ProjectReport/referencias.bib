
@book{sanchez2007gestion,
  title={Gesti\'{o}n y Minimizaci\'{o}n de Residuos},
  author={S\'{a}nchez, M.F. and Castro, J.G.},
  isbn={9788496743342},
  url={https://books.google.es/books?id=uMdNfGpLUKcC},
  year={2007},
  publisher={Fundaci\'{o}n Confemetal}
}

@article{Emergencia2019,
	author={Carlos Alfonso and 
			Ra\'{u}l Est\'{e}vez Est\'{e}vez and
			Jorge M. Lobo and
			Begoña Lozano Di\'{e}guez and
			Fernando Prieto and
			Jos\'{e} Santamarta and
			\'{A}lvaro Gaerter},
	year = 2016,
	month = {Diciembre},
	title={Emergencia clim\'{a}tica en {Espa\~{n}a}},
	organization = {Observatorio Sostenibilidad}
}

@book{fonfria1989ingenieria,
  title={Ingenier\'{i}a ambiental: contaminaci\'{o}n y tratamientos},
  author={Fonfr\'{i}a, R.S. and Sans, R. and de Pablo Ribas, J.},
  isbn={9788426707420},
  series={Colecci\'{o}n productiva},
  url={https://books.google.es/books?id=kumplOJs6T0C},
  year={1989},
  publisher={Marcombo}
}

@Book{Karim2018,
    author = {Rezaul Karim},
    title = {TensorFlow: Powerful Predictive Analytics with TensorFlow},
    publisher = {Packt Publishing, Limited},
    year = {2018}
}

@Inbook{Wang2003,
    author={Wang, Sun-Chong},
    title={Artificial Neural Network},
    bookTitle={Interdisciplinary Computing in Java Programming},
    year={2003},
    publisher={Springer US},
    address={Boston, MA},
    pages={81--100},
    abstract={Inspired by the sophisticated functionality of human brains where hundreds of billions    of interconnected neurons process information in parallel, researchers have successfully tried demonstrating certain levels of intelligence on silicon. Examples include language translation and pattern recognition software. While simulation of human consciousness and emotion is still in the realm of science fiction, we, in this chapter, consider artificial neural networks as universal function approximators. Especially, we introduce neural networks which are suited for time series forecasts.},
    isbn={978-1-4615-0377-4},
    doi={10.1007/978-1-4615-0377-4_5},
    url={https://doi.org/10.1007/978-1-4615-0377-4_5}
}



@article{Dai_2020,
	doi = {10.1088/1742-6596/1651/1/012114},
	url = {https://doi.org/10.1088/1742-6596/1651/1/012114},
	year = {2020},
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {1651},
	pages = {012114},
	author = {Junyan Dai},
	title = {Real-time and accurate object detection on edge device with {TensorFlow} Lite},
	journal = {Journal of Physics: Conference Series},
	abstract = {Objection detection is of vital importance to many fields, such as autonomous driving, outdoor robotics, and computer vision. Existing approaches on object detection can hardly run on the resource-constrained edge devices. In order to mitigate this dilemma, we propose to apply TensorFlow Lite to convert Float32 neural network model to unit8 neural network with subtle or even no accuracy loss. Two advantages are here for conversion. First, it reduces the model size to a quarter so that it fits for devices with limited storage. Second, it achieves much faster inference time. I conduct an experiment on MSCOCO dataset. Experimental results show that our proposed method achieves mAP 72.1 and FPS 23 on edge device.}
}

@misc{tensorflow2015-whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015}
}

@mastersthesis{Alsing2018,
   author = {Alsing, Oscar},
   institution = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   school = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   title = {Mobile Object Detection using TensorFlow Lite and Transfer Learning},
   series = {TRITA-EECS-EX},
   number = {2018:535},
   keywords = {cnn, convolutional neural networks, transfer learning, mobile object detection},
   abstract = {With the advancement in deep learning in the past few years, we are able to create complex machine learning models for detecting objects in images, regardless of the characteristics of the objects to be detected. This development has enabled engineers to replace existing heuristics-based systems in favour of machine learning models with superior performance. In this report, we evaluate the viability of using deep learning models for object detection in real-time video feeds on mobile devices in terms of object detection performance and inference delay as either an end-to-end system or feature extractor for existing algorithms. Our results show a significant increase in object detection performance in comparison to existing algorithms with the use of transfer learning on neural networks adapted for mobile use. },
   year = {2018}
}

@misc{howard2017mobilenets,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{iandola2016squeezenet,
      title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}, 
      author={Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
      year={2016},
      eprint={1602.07360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{LiShuangfeng1839,
author = {Li Shuangfeng},
title = {TensorFlow Lite: On-Device Machine Learning Framework},
publisher = {Journal of Computer Research and Development},
year = {2020},
journal = {Journal of Computer Research and Development},
volume = {57},
number = {9},
eid = {1839},
numpages = {14},
pages = {1839},
keywords = {machine learning; on-device machine learning (ODML); TensorFlow; TensorFlow Lite; TFLite; mobile; IoT},
url = {https://crad.ict.ac.cn/EN/abstract/article_4251.shtml},
doi = {10.7544/issn1000-1239.2020.20200291}
}   

@article{merlin2020squeeze,
  title={Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition},
  author={Merlin Albes, Zhao Ren and Schuller, Bj{\"o}rn W and Cummins, Nicholas},
  year={2020}
}

@INPROCEEDINGS{7844626,  
	author={Paul, Rahul and Hawkins, 
			Samuel H. and Hall, 
			Lawrence O. and Goldgof, 
			Dmitry B. and 	
			Gillies, Robert J.},  
	booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},   	
	title={Combining deep neural network and traditional image features to improve survival prediction accuracy for lung cancer patients from diagnostic CT},   
	year={2016},  
	pages={002570-002575},  
	doi={10.1109/SMC.2016.7844626},
	url = {https://ieeexplore.ieee.org/abstract/document/7844626}
}

@unpublished{Aitor2019Signos,
           month = {Julio},
           title = {Desarrollo de un sistema autom{\'a}tico de reconocimiento de lenguaje de signos},
          author = {Aitor Alc{\'a}zar Fern{\'a}ndez},
         address = {Madrid},
            year = {2019},
        keywords = {Personas con discapacidad; Redes neuronales; Reconocimiento de im{\'a}genes},
             url = {http://oa.upm.es/56626/},
        abstract = {Actualmente, las personas con discapacidades auditivas y del habla recurren al lenguaje de signos para comunicarse entre s{\'i}, pero es una actividad que {\'u}nicamente se puede realizar de forma presencial y entre personas que conozcan dicha lengua. Para poder establecer la comunicaci{\'o}n con el resto de las personas, es necesario recurrir a un intermediario o traductor, que haga las veces de emisor y receptor entre ambos. Esto resulta poco pr{\'a}ctico y, en la mayor{\'i}a de las ocasiones, costoso. Se pretende con este proyecto desarrollar un sistema capaz de traducir en tiempo real la detecci{\'o}n de signos aislados de la lengua de signos americana (American Sign Language - ASL). El software consiste en una inteligencia artificial entrenada para monitorizar los movimientos de las manos de la persona situada frente a la c{\'a}mara de un terminal m{\'o}vil, y mostrar por pantalla el signo traducido en ese momento sobre la imagen captada. Para ello, se han seguido dos l{\'i}neas de investigaci{\'o}n: con la primera, se ha desarrollado un traductor del alfabeto de la ASL recogiendo im{\'a}genes desde una c{\'a}mara IP en un terminal m{\'o}vil, procesando los datos y mostrando los resultados en el ordenador. La segunda l{\'i}nea de investigaci{\'o}n ha sido m{\'a}s ambiciosa, pues se ha conseguido traducir cuatro signos din{\'a}micos aislados, y desplegar el sistema creado en un terminal m{\'o}vil Android, el cual ejecuta una aplicaci{\'o}n aut{\'o}noma de traducci{\'o}n de estos signos en tiempo real. Gracias al desarrollo de este sistema, el grado de adaptaci{\'o}n para las personas con dichas dificultades comunicativas puede lograr un crecimiento de gran magnitud en distintos aspectos: de manera social, dando pie a una comunicaci{\'o}n m{\'a}s amplia y acercando la ASL a todos; cultural, educando a las personas que carecen de los conocimientos necesarios para comunicarse con ellos; y econ{\'o}mico, pues supone abaratar los costes relacionados con traductores personales y cursos formativos.}
}

@book{sanchez2007gestion,
  title={Gesti\'{o}n y Minimizaci\'{o}n de Residuos},
  author={S\'{a}nchez, M.F. and Castro, J.G.},
  isbn={9788496743342},
  url={https://books.google.es/books?id=uMdNfGpLUKcC},
  year={2007},
  publisher={Fundaci\'{o}n Confemetal}
}

@article{Emergencia2019,
	author={Alfonso, C and 
			Est\'{e}vez Est\'{e}vez, R and
			Lobo, J. M. and
			Lozano Di\'{e}guez, B. and
			Prieto, F. and
			Santamarta, J. and
			Gaerter, A.},
	year = 2016,
	month = {Diciembre},
	title={Emergencia clim\'{a}tica en {Espa\~{n}a}},
	organization = {Observatorio Sostenibilidad}
}
%	author={Carlos Alfonso and 
%			Ra\'{u}l Est\'{e}vez Est\'{e}vez and
%			Jorge M. Lobo and
%			Begoña Lozano Di\'{e}guez and
%			Fernando Prieto and
%			Jos\'{e} Santamarta and
%			\'{A}lvaro Gaerter},


@book{fonfria1989ingenieria,
  title={Ingenier\'{i}a ambiental: contaminaci\'{o}n y tratamientos},
  author={Fonfr\'{i}a, R.S. and Sans, R. and de Pablo Ribas, J.},
  isbn={9788426707420},
  series={Colecci\'{o}n productiva},
  url={https://books.google.es/books?id=kumplOJs6T0C},
  year={1989},
  publisher={Marcombo}
}

@Book{Karim2018,
    author = {Rezaul Karim},
    title = {TensorFlow: Powerful Predictive Analytics with TensorFlow},
    publisher = {Packt Publishing, Limited},
    year = {2018}
}

@Inbook{Wang2003,
    author={Wang, Sun-Chong},
    title={Artificial Neural Network},
    bookTitle={Interdisciplinary Computing in Java Programming},
    year={2003},
    publisher={Springer US},
    address={Boston, MA},
    abstract={Inspired by the sophisticated functionality of human brains where hundreds of billions    of interconnected neurons process information in parallel, researchers have successfully tried demonstrating certain levels of intelligence on silicon. Examples include language translation and pattern recognition software. While simulation of human consciousness and emotion is still in the realm of science fiction, we, in this chapter, consider artificial neural networks as universal function approximators. Especially, we introduce neural networks which are suited for time series forecasts.},
    isbn={978-1-4615-0377-4},
    doi={10.1007/978-1-4615-0377-4_5},
    url={https://doi.org/10.1007/978-1-4615-0377-4_5}
}



@article{Dai_2020,
	doi = {10.1088/1742-6596/1651/1/012114},
	url = {https://doi.org/10.1088/1742-6596/1651/1/012114},
	year = {2020},
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {1651},
	author = {Junyan Dai},
	title = {Real-time and accurate object detection on edge device with {TensorFlow} Lite},
	journal = {Journal of Physics: Conference Series},
	abstract = {Objection detection is of vital importance to many fields, such as autonomous driving, outdoor robotics, and computer vision. Existing approaches on object detection can hardly run on the resource-constrained edge devices. In order to mitigate this dilemma, we propose to apply TensorFlow Lite to convert Float32 neural network model to unit8 neural network with subtle or even no accuracy loss. Two advantages are here for conversion. First, it reduces the model size to a quarter so that it fits for devices with limited storage. Second, it achieves much faster inference time. I conduct an experiment on MSCOCO dataset. Experimental results show that our proposed method achieves mAP 72.1 and FPS 23 on edge device.}
}

@misc{tensorflow2015whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015}
}

@mastersthesis{Alsing2018,
   author = {Alsing, Oscar},
   institution = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   school = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   title = {Mobile Object Detection using TensorFlow Lite and Transfer Learning},
   series = {TRITA-EECS-EX},
   number = {2018:535},
   keywords = {cnn, convolutional neural networks, transfer learning, mobile object detection},
   abstract = {With the advancement in deep learning in the past few years, we are able to create complex machine learning models for detecting objects in images, regardless of the characteristics of the objects to be detected. This development has enabled engineers to replace existing heuristics-based systems in favour of machine learning models with superior performance. In this report, we evaluate the viability of using deep learning models for object detection in real-time video feeds on mobile devices in terms of object detection performance and inference delay as either an end-to-end system or feature extractor for existing algorithms. Our results show a significant increase in object detection performance in comparison to existing algorithms with the use of transfer learning on neural networks adapted for mobile use. },
   year = {2018}
}

@misc{howard2017mobilenets,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{iandola2016squeezenet,
      title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}, 
      author={Forrest N. Iandola and 
      		  Song Han and 
      		  Matthew W. Moskewicz and 
      		  Khalid Ashraf and 
      		  William J. Dally 
      		  and Kurt Keutzer},
      year={2016},
      eprint={1602.07360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{LiShuangfeng1839,
	author = {Li Shuangfeng},
	title = {TensorFlow Lite: On-Device Machine Learning Framework},
	publisher = {Journal of Computer Research and Development},
	year = {2020},
	journal = {Journal of Computer Research and Development},
	volume = {57},
	number = {9},
	eid = {1839},
	numpages = {14},
	keywords = {machine learning; on-device machine learning (ODML); TensorFlow; TensorFlow Lite; TFLite; mobile; IoT},
	url = {https://crad.ict.ac.cn/EN/abstract/article_4251.shtml},
	doi = {10.7544/issn1000-1239.2020.20200291}
}   

@article{merlin2020squeeze,
  title={Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition},
  author={Merlin Albes, Zhao Ren and Schuller, Bj{\"o}rn W and Cummins, Nicholas},
  year={2020}
}

@INPROCEEDINGS{7844626,  
	author={Paul, Rahul and Hawkins, 
			Samuel H. and Hall, 
			Lawrence O. and Goldgof, 
			Dmitry B. and 	
			Gillies, Robert J.},  
	booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},   	
	title={Combining deep neural network and traditional image features to improve survival prediction accuracy for lung cancer patients from diagnostic CT},   
	year={2016},  
	doi={10.1109/SMC.2016.7844626},
	url = {https://ieeexplore.ieee.org/abstract/document/7844626}
}

@unpublished{Aitor2019Signos,
           month = {Julio},
           title = {Desarrollo de un sistema autom{\'a}tico de reconocimiento de lenguaje de signos},
          author = {Aitor Alc{\'a}zar Fern{\'a}ndez},
         address = {Madrid},
            year = {2019},
        keywords = {Personas con discapacidad; Redes neuronales; Reconocimiento de im{\'a}genes},
             url = {http://oa.upm.es/56626/},
        abstract = {Actualmente, las personas con discapacidades auditivas y del habla recurren al lenguaje de signos para comunicarse entre s{\'i}, pero es una actividad que {\'u}nicamente se puede realizar de forma presencial y entre personas que conozcan dicha lengua. Para poder establecer la comunicaci{\'o}n con el resto de las personas, es necesario recurrir a un intermediario o traductor, que haga las veces de emisor y receptor entre ambos. Esto resulta poco pr{\'a}ctico y, en la mayor{\'i}a de las ocasiones, costoso. Se pretende con este proyecto desarrollar un sistema capaz de traducir en tiempo real la detecci{\'o}n de signos aislados de la lengua de signos americana (American Sign Language - ASL). El software consiste en una inteligencia artificial entrenada para monitorizar los movimientos de las manos de la persona situada frente a la c{\'a}mara de un terminal m{\'o}vil, y mostrar por pantalla el signo traducido en ese momento sobre la imagen captada. Para ello, se han seguido dos l{\'i}neas de investigaci{\'o}n: con la primera, se ha desarrollado un traductor del alfabeto de la ASL recogiendo im{\'a}genes desde una c{\'a}mara IP en un terminal m{\'o}vil, procesando los datos y mostrando los resultados en el ordenador. La segunda l{\'i}nea de investigaci{\'o}n ha sido m{\'a}s ambiciosa, pues se ha conseguido traducir cuatro signos din{\'a}micos aislados, y desplegar el sistema creado en un terminal m{\'o}vil Android, el cual ejecuta una aplicaci{\'o}n aut{\'o}noma de traducci{\'o}n de estos signos en tiempo real. Gracias al desarrollo de este sistema, el grado de adaptaci{\'o}n para las personas con dichas dificultades comunicativas puede lograr un crecimiento de gran magnitud en distintos aspectos: de manera social, dando pie a una comunicaci{\'o}n m{\'a}s amplia y acercando la ASL a todos; cultural, educando a las personas que carecen de los conocimientos necesarios para comunicarse con ellos; y econ{\'o}mico, pues supone abaratar los costes relacionados con traductores personales y cursos formativos.}
}

@misc{benchmark2020comparison,
      title={Comparison and Benchmarking of AI Models and Frameworks on Mobile Devices}, 
      author={Chunjie Luo and 
      		  Xiwen He and 
      		  Jianfeng Zhan and 
      		  Lei Wang and 
      		  Wanling Gao and 
      		  Jiahui Dai},
      year={2020},
      eprint={2005.05085},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{pytorch2019,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and 
      		  Sam Gross and 
      		  Francisco Massa and 
      		  Adam Lerer and 
      		  James Bradbury and 
      		  Gregory Chanan and 
      		  Trevor Killeen and 
      		  Zeming Lin and 
      		  Natalia Gimelshein and 
      		  Luca Antiga and 
      		  Alban Desmaison and 
      		  Andreas Köpf and 
      		  Edward Yang and 
      		  Zach DeVito and 
      		  Martin Raison and 
      		  Alykhan Tejani and 
      		  Sasank Chilamkurthy and 
      		  Benoit Steiner and 
      		  Lu Fang and 
      		  Junjie Bai and 
      		  Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{unsupervised2013,
  author={Le, Quoc V. and 
  		  Aurelio Ranzato, Marc' and
  		  Monga, Rajat and
  		  Devin, Matthieu and
  		  Chan, Kai and
  		  Corrado, Greg S. and
  		  Dean, Jeff and
  		  Ng, Andrew Y.},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Building high-level features using large scale unsupervised learning}, 
  year={2013},
  volume={},
  number={},
  doi={10.1109/ICASSP.2013.6639343}
}
  
@book{warden2019tinyml,
  title={TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
  author={Warden, P. and Situnayake, D.},
  isbn={9781492051992},
  url={https://books.google.es/books?id=tH3EDwAAQBAJ},
  year={2019},
  publisher={O'Reilly Media}
}

@InProceedings{mobilenev22018,
	author = {Sandler, Mark and 
		  Howard, Andrew and 
		  Zhu, Menglong and 
		  Zhmoginov, Andrey and 
		  Chen, Liang-Chieh},
	title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2018}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and 
      		  Jean Pouget-Abadie and 
      		  Mehdi Mirza and 
      		  Bing Xu and 
      		  David Warde-Farley and 
      		  Sherjil Ozair and 
      		  Aaron Courville and 
      		  Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}
}

@InProceedings{synthia2016,
	author = {Ros, German and 
			  Sellart, Laura and 
			  Materzynska, Joanna and 
			  Vazquez, David and 
			  Lopez, Antonio M.},
	title = {The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016},
	url={http://synthia-dataset.net/}
}

@inproceedings{industrialdetection2020,
  TITLE = {{CAD-based Learning for Egocentric Object Detection in Industrial Context}},
  AUTHOR = {Cohen, Julia and 
  		    Crispim-Junior, Carlos F. and 
  		    Grange-Faivre, C{\'e}line and 
  		    Tougne, Laure},
  URL = {https://hal.archives-ouvertes.fr/hal-02553622},
  BOOKTITLE = {{15th International Conference on Computer Vision Theory and Applications}},
  ADDRESS = {Valletta, Malta},
  PUBLISHER = {{SCITEPRESS - Science and Technology Publications}},
  VOLUME = {5},
  YEAR = {2020},
  MONTH = Feb,
  DOI = {10.5220/0008975506440651},
  KEYWORDS = {Object Detection ; Egocentric ; Database Generation},
  PDF = {https://hal.archives-ouvertes.fr/hal-02553622/file/VISAPP_camera-ready.pdf},
  HAL_ID = {hal-02553622},
  HAL_VERSION = {v1},
}

@inproceedings{lepetit2008,
   title = {Simultaneous Recognition and Homography Extraction of Local Patches with a Simple Linear Classifier},
   author = {Hinterstoisser, S. and 
   			 Benhimane, S. and 
   			 Lepetit, V. and 
   			 Fua, P. and 
   			 Navab, N.},
   year = {2008},
   booktitle = {Proceedings of the British Machine Vision Conference},
   publisher = {BMVA Press},
   editors = {Everingham, M. and Needham, C.},
   isbn = {1-901725-36-7},
   note = {doi:10.5244/C.22.10},
   url={http://www.bmva.org/bmvc/2008/papers/16.html}
}

@misc{synthdet2020,
    title={Training a performant object detection {ML} model on synthetic data using {U}nity {P}erception tools},
    author={You-Cyuan Jhang and 
    		Adam Palmar and 
    		Bowen Li and 
    		Saurav Dhakad and 
    		Sanjay Kumar Vishwakarma and 
    		Jonathan Hogins and 
    		Adam Crespi and 
    		Chris Kerr and 
    		Sharmila Chockalingam and 
    		Cesar Romero and 
    		Alex Thaman and 
    		Sujoy Ganguly},
    url = {https://blogs.unity3d.com/2020/09/17/training-a-performant-object-detection-ml-model-on-synthetic-data-using-unity-computer-vision-tools/},
    journal={Unity Technologies Blog},
    publisher={Unity Technologies},
    year={2020},
    month={Sep}
}

@misc{perception2021,
    title={Unity {P}erception Package},
    author={{Unity Technologies}},
    url = {https://github.com/Unity-Technologies/com.unity.perception},
    year={2020}
}

@article{amazongo2018,
  title={The amazon go concept: Implications, applications, and sustainability},
  author={Polacco, Alex and Backes, Kayla},
  journal={Journal of Business and Management},
  volume={24},
  number={1},
  year={2018},
}

@article{lepetitdrones2014,
	author = {Rozantsev, Artem and 
			  Lepetit, Vincent and 
			  Fua, Pascal},
	year = {2014},
	month = {11},
	title = {On Rendering Synthetic Images for Training an Object Detector},
	volume = {137},
	journal = {Computer Vision and Image Understanding},
	doi = {10.1016/j.cviu.2014.12.006},
	url={https://www.researchgate.net/publication/268987900_On_Rendering_Synthetic_Images_for_Training_an_Object_Detector}
}

@book{cyganek2013object,
  title={Object Detection and Recognition in Digital Images: Theory and Practice},
  author={Cyganek, B.},
  isbn={9781118618363},
  lccn={2012050754},
  url={https://ebookcentral.proquest.com/lib/universidadcomplutense-ebooks/detail.action?docID=1204058\#},
  year={2013},
  publisher={Wiley}
}

@Inbook{objectdetection2020,
	author={Amit, Yali and 
			Felzenszwalb, Pedro and 
			Girshick, Ross},
	title={Object Detection},
	bookTitle={Computer Vision: A Reference Guide},
	year={2020},
	publisher={Springer International Publishing},
	address={Cham},
	isbn={978-3-030-03243-2},
	doi={10.1007/978-3-030-03243-2_660-1},
	url={https://doi.org/10.1007/978-3-030-03243-2_660-1}
}

@book{amit20022d,
  title={2D Object Detection and Recognition: Models, Algorithms, and Networks},
  author={Amit, Y.},
  isbn={9780262011945},
  lccn={2002016508},
  series={Mit Press},
  url={https://books.google.es/books?id=3gJIX\_NmNG4C},
  year={2002},
  publisher={MIT Press}
}

@article{polacco2018amazon,
  title={The amazon go concept: Implications, applications, and sustainability},
  author={Polacco, Alex and Backes, Kayla},
  journal={Journal of Business and Management},
  volume={24},
  number={1},
  year={2018},
}

@book{vocus2006,
  title={VOCUS: A visual attention system for object detection and goal-directed search},
  author={Frintrop, Simone},
  volume={3899},
  year={2006},
  publisher={Springer}
}

@book{michelucci2019advanced,
  title={Advanced applied deep learning: convolutional neural networks and object detection},
  author={Michelucci, Umberto},
  year={2019},
  publisher={Springer}
}

@book{jiang2019deep,
  title={Deep Learning in object detection and recognition},
  author={Jiang, Xiaoyue and 
  		  Hadid, Abdenour and 
  		  Pang, Yanwei and 
  		  Granger, Eric and 
  		  Feng, Xiaoyi},
  year={2019},
  publisher={Springer}
}

@article{matriculas2006,
  title={Reconocimiento autom{\'a}tico de matr{\'\i}culas},
  author={Parra Ramos, Carlos and Regajo Rodr{\'\i}guez, David },
  journal={Universidad Carlos III de Madrid},
  year={2006}
}

@book{lopez2008redes,
  title={Las Redes Neuronales Artificiales},
  author={Flórez L{\'o}pez, Raquel and 
  		  Fern{\'a}ndez, Jos{\'e} Miguel and 
  		  Fern{\'a}ndez Fern{\'a}ndez, Jos{\'e} Miguel},
  isbn={9788497452465},
  series={Metodolog{\'\i}a y An{\'a}lisis de Datos en Ciencias Sociales},
  url={https://books.google.es/books?id=X0uLwi1Ap4QC},
  year={2008},
  publisher={Netbiblo}
}

@book{zurada1992introduction,
  title={Introduction to Artificial Neural Systems},
  author={Zurada, J.M.},
  isbn={9780314933911},
  lccn={92000712},
  url={https://books.google.es/books?id=wLFQAAAAMAAJ},
  year={1992},
  publisher={West}
}

@book{rnafundamentos1995,
	author = {Hilera, Jos{\'e} R. and Mart{\'i}nez Hernando, V{\'i}ctor J.},
	year = {1995},	
	month = {01},
	title = {Redes neuronales artificiales:~fundamentos, modelos y aplicaciones},
	journal = {SERBIULA (sistema Librum 2.0)}
}

@book{muller1995neural,
  title={Neural Networks: An Introduction},
  author={M{\"u}ller, B. and Reinhardt, J. and Strickland, M.T.},
  isbn={9783540602071},
  lccn={lc95024948},
  series={Physics of Neural Networks},
  url={https://books.google.es/books?id=EFUzMYjOXk8C},
  year={1995},
  publisher={Springer Berlin Heidelberg}
}

@article{annealing2004,
	author = {G{\'o}mez Rojas, German Alonso and 
			  Henao L{\'o}pez, Juan Carlos and 
			  Salazar Isaza, Harold},
	year = {2004},
	title = {ENTRENAMIENTO DE UNA RED NEURONAL ARTIFICIAL USANDO EL ALGORITMO SIMULATED ANNEALING},
	journal = {Scientia Et Technica}
}

@article{larranaga1997tema,
  title={Tema 8. redes neuronales},
  author={Larranaga, Pedro and 
  		  Inza, Inaki and 
  		  Moujahid, Abdelmalik},
  journal={Redes Neuronales, U. del P. Vasco},
  volume={12},
  year={1997}
}

@article{firstrna1943,
  title={A logical calculus of the ideas immanent in nervous activity},
  author={McCulloch, Warren S. and Pitts, Walter},
  journal={The bulletin of mathematical biophysics},
  volume={5},
  number={4},
  year={1943},
  publisher={Springer}
}

@InProceedings{yolo2016,
	author = {Redmon, Joseph and 
			  Divvala, Santosh and 
			  Girshick, Ross and 
			  Farhadi, Ali},
	title = {You Only Look Once: Unified, Real-Time Object Detection},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016}
}

@article{pacheco2017identificacion,
  title={Identificaci{\'o}n de sistemas no lineales con redes neuronales convolucionales},
  author={L{\'o}pez Pacheco, Mario Antonio},
  journal={Cuidad de Mexico: Centro de investigación y de estudios avanzados},
  year={2017}
}

@unpublished{movcorporalespavon2020,
           title = {T{\'e}cnicas de Deep Learning para el reconocimiento de movimientos corporales},
            year = {2020},
            note = {Trabajo de Fin de Grado en Ingenier{\'i}a del Software, Facultad de Inform{\'a}tica UCM, Departamento de Ingenier{\'i}a de Software e Inteligencia Artificial, Curso 2019/2020},
        keywords = {Redes neuronales recurrentes (RNN) - Memoria a corto y largo plazo (LSTM) - Reconocimiento de actividades humanas (HAR) - Interfaz de programaci{\'o}n de aplicaciones (API) - Aprendizaje profundo - Predicci{\'o}n},
             url = {https://eprints.ucm.es/id/eprint/61674/},
        abstract = {En este trabajo se detalla el dise{\~n}o y desarrollo de un sistema de reconocimiento de actividades humanas (HAR, human activity recognition) mediante redes neuronales, as{\'i} como la labor de investigaci{\'o}n realizada sobre t{\'e}cnicas y proyectos similares realizados sobre este mismo campo. El sistema desarrollado consta de varios m{\'o}dulos que hacen uso e interact{\'u}an a trav{\'e}s de internet, estando en parte alojados en la nube. 
Concretamente, el dise{\~n}o de la aplicaci{\'o}n contiene dos m{\'o}dulos principales, una aplicaci{\'o}n m{\'o}vil para sistemas Android y una aplicaci{\'o}n web alojada en un servidor. La primera, instalada en un dispositivo m{\'o}vil, recaba datos de los sensores del dispositivo (sensores de aceleraci{\'o}n y movimiento) y los env{\'i}a al servidor por internet para ser analizados. La aplicaci{\'o}n web consiste en una api REST, que hace uso de una red neuronal entrenada para realizar predicciones sobre la actividad que se est{\'a} realizando, bas{\'a}ndose en los datos recibidos. El tipo de red empleado es una red recurrente de tipo Long-Short-Term Memory (LSTM), basada en los trabajos publicados por Matlab sobre clasificaci{\'o}n y predicci{\'o}n sequence-to-sequence. Esta herramienta es tambi{\'e}n la que se ha empleado para desarrollar el modelo de red y realizar los entrenamientos necesarios. 
El proceso de predicci{\'o}n se inicia cuando el usuario selecciona la opci{\'o}n correspondiente en su dispositivo m{\'o}vil. Desde ese momento, cada dos cent{\'e}simas de segundo se env{\'i}a por internet un paquete de datos al servidor, conteniendo informaci{\'o}n sobre la situaci{\'o}n actual en la que se encuentra el aparato seg{\'u}n la actividad que se est{\'e} realizando. El servidor analiza cada uno de estos paquetes, los procesa y se los pasa a la red neuronal. {\'E}sta realiza una predicci{\'o}n, con cierto grado de seguridad, que se almacena en la base de datos del servidor. Adem{\'a}s de realizar predicciones, la aplicaci{\'o}n m{\'o}vil permite tambi{\'e}n enviar datos con una clase asociada relativa a la actividad que se est{\'a} realizando. Estos datos se almacenan tambi{\'e}n en la base de datos y se pueden utilizar posteriormente para reentrenar la red y realizar nuevas pruebas. 
Al acceder a la aplicaci{\'o}n web a trav{\'e}s de una URL desde un navegador, se puede abrir una p{\'a}gina web donde se muestra, en tiempo real, la actividad que la red predice que est{\'a} realizando actualmente el usuario que lleva el dispositivo m{\'o}vil, junto con el porcentaje de acierto respecto de la predicci{\'o}n realizada. 
Se describen las fases de desarrollo de la aplicaci{\'o}n comenzando por el estudio y an{\'a}lisis de algoritmos de deep-learning a este {\'a}mbito de reconocimiento de actividades humanas, as{\'i} como todo el proceso de ensayo y pruebas realizado sobre distintos modelos de redes para obtener los resultados m{\'a}s {\'o}ptimos, con resultados satisfactorios.},
          author = {Pav{\'o}n Ben{\'i}tez, Roberto}
}

@mastersthesis{guridi2017modelos,
  title={Modelos de redes neuronales recurrentes en clasificaci{\'o}n de patentes},
  author={Guridi Mateos, Guillermo and others},
  type={{B.S.} thesis},
  year={2017}
}

@article{matich2001conceptos,
  title={Redes Neuronales: Conceptos b{\'a}sicos y aplicaciones},
  author={Matich, Dami{\'a}n Jorge},
  journal={Universidad Tecnol{\'o}gica Nacional, M{\'e}xico},
  volume={41},
  year={2001}
}

@article{basogain2008redes,
  title={Redes neuronales artificiales y sus aplicaciones},
  author={Basogain Olabe, Xavier},
  journal={Dpto. Ingenier{\'\i}a de Sistemas y Autom{\'a}tica, Escuela Superior de Ingenier{\'\i}a Bilbao. Open Course Ware.[En l{\'\i}nea] disponible en http://ocw. ehu. es/ensenanzas-tecnicas/redes-neuronales-artificiales-y-sus-aplicaciones/Course\_ listing.[Consultada 20-09-2012]},
  year={2008}
}

@article{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and 
  		  Sutskever, Ilya and 
  		  Hinton, Geoffrey E},
  journal={Advances in neural information processing systems},
  volume={25},
  year={2012}
}

@unpublished{cortina2020automata,
           title = {T{\'e}cnicas inteligentes para su integraci{\'o}n en un veh{\'i}culo aut{\'o}mata},
            year = {2020},
            note = {Trabajo de Fin de Grado en Ingenier{\'i}a del Software, Facultad de Inform{\'a}tica UCM, Departamento de Ingenier{\'i}a del Software e Inteligencia Artificial, Curso 2019/2020.},
        keywords = {Veh{\'i}culo aut{\'o}mata, Visi{\'o}n artificial, Aprendizaje profundo, Red neuronal convolucional, Entrenamiento, Clasificaci{\'o}n, Raspberry Pi.},
             url = {https://eprints.ucm.es/id/eprint/62015/},
        abstract = {Es evidente que los veh{\'i}culos aut{\'o}nomos de futuro constituyen un nicho de inter{\'e}s tecnol{\'o}gico elevado. La dotaci{\'o}n de inteligencia a los mismos es, a su vez, un reto. Es bajo esta perspectiva sobre la que se plantea el presente trabajo, si bien a muy peque{\~n}a escala.
En efecto se propone el desarrollo de un prototipo de veh{\'i}culo aut{\'o}nomo dotado de inteligencia, esto es, un aut{\'o}mata inteligente. El modelo de prototipo, en l{\'i}nea con desarrollos de este tipo, se plantea considerando una plataforma dotada con los elementos necesarios para navegaci{\'o}n aut{\'o}noma, incluyendo ruedas, motores, alimentaci{\'o}n, por supuesto sensores de visi{\'o}n (c{\'a}mara) y de proximidad (ultrasonidos) y naturalmente un computador local basado en una Raspberry Pi que gestiona y controla las acciones del veh{\'i}culo. El sistema tambi{\'e}n consta de un computador remoto, en perfecta comunicaci{\'o}n y sincron{\'i}a con el local donde se realizan los procesos con alta carga computacional y donde est{\'a} instalada la parte inteligente del sistema.
El computador local env{\'i}a datos (im{\'a}genes y distancias) al remoto, inici{\'a}ndose en {\'e}ste su procesamiento. En el caso de las im{\'a}genes mediante la aplicaci{\'o}n de t{\'e}cnicas de segmentaci{\'o}n para localizar una plataforma con una base rectangular negra conteniendo figuras geom{\'e}tricas (cuadrado, c{\'i}rculo, rect{\'a}ngulo, tri{\'a}ngulo) de color en su interior, y que constituye el objetivo del veh{\'i}culo hacia el que se tiene que dirigir. Con tal finalidad, se extraen regiones candidatas, que pueden contener la plataforma, aplicando t{\'e}cnicas de umbralizaci{\'o}n y etiquetado de componentes conexas, para proceder a recortar dichas regiones sobre la imagen original. Estos recortes se pasan a una Red Neuronal Convolucional, previamente re-entrenada a partir del modelo AlexNet, que proporciona un valor de probabilidad para determinar si el recorte puede o no considerarse como la plataforma. Un proceso posterior, basado en la identificaci{\'o}n de las figuras geom{\'e}tricas de la plataforma refuerza o penaliza la probabilidad dada por la red, procediendo a decidir si la regi{\'o}n analizada es o no finalmente la plataforma. En el caso de las distancias, proporcionadas por el sensor de ultrasonidos, simplemente se trata de verificar la proximidad del veh{\'i}culo a un objeto o a la plataforma, para confirmar la llegada al objetivo. Esta informaci{\'o}n se transmite a la Raspberry Pi, que se convierte en acciones sobre el veh{\'i}culo para girar, avanzar y seguir o no enviando m{\'a}s datos desde el veh{\'i}culo. 
Los experimentos realizados han verificado la validez de la propuesta, destacando los aspectos relacionados con el sistema inteligente y la navegaci{\'o}n aut{\'o}noma del veh{\'i}culo aut{\'o}mata.},
          author = {Cortina Fern{\'a}ndez, Guillermo}
}

@inproceedings{comparinalexnetvgg2016,
  title={Visualizing and Comparing AlexNet and VGG using Deconvolutional Layers},
  author={Wei Yu and Y. Bai},
  year={2016}
}

@article{simonyan2014vgg,
  title={Very deep convolutional networks for large-scale image recognition},
  author={Simonyan, Karen and Zisserman, Andrew},
  journal={arXiv preprint arXiv:1409.1556},
  year={2014}
}

@inproceedings{inceptionnet2015,
  title={Going deeper with convolutions},
  author={Szegedy, Christian and Liu, Wei and Jia, Yangqing and Sermanet, Pierre and Reed, Scott and Anguelov, Dragomir and Erhan, Dumitru and Vanhoucke, Vincent and Rabinovich, Andrew},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  year={2015}
}

@article{unityhistory2014,
  title={A history of the unity game engine},
  author={Haas, John},
  journal={Diss. WORCESTER POLYTECHNIC INSTITUTE},
  year={2014}
}

@book{halpern2019developing,
  title={Developing 2D Games with Unity},
  author={Halpern, Jared and Halpern},
  year={2019},
  publisher={Springer}
}

@misc{futureclimatechange,
    author = {Anthony J. McMichael and 
    		  Diarmid Campbell-Lendrum and 
    		  Sari Kovats and 
    		  Sally Edwards and 
    		  Paul Wilkinson and 
    		  Theresa Wilson and 
    		  Robert Nicholls and 
    		  Simon Hales and 
    		  Frank Tanser and 
    		  David Le Sueur and 
    		  Michael Schlesinger and 
    		  Natasha Andronova},
    title = {Chapter 20 Global climate change}
}

@article{caballero2007efecto,
  title={Efecto invernadero, calentamiento global y cambio clim{\'a}tico: una perspectiva desde las ciencias de la tierra},
  author={Caballero, Margarita and 
  		  Lozano, Socorro and 
  		  Ortega, Beatriz},
  journal={Revista digital universitaria},
  volume={8},
  year={2007}
}

@article{informe2020WWF,
  title={WWF (2020) Living Planet Report 2020 -
Bending the curve of biodiversity loss. },
  author={Almond, R.E.A. and Grooten M. and Petersen, T.},
  year={2020},
  journal={World Wildlife Fund (WWF)},
  ISBN={ISBN 978-2-940529-99-5}

}

@mastersthesis{shirley2010analisis,
  title={An{\'a}lisis de las necesidades y dificultades en la disposici{\'o}n de residuos s{\'o}lidos en la fuente dom{\'e}stica para el desarrollo de un producto},
  author={Iguar{\'a}n Guerra, Andrea and G{\'o}mez Ru{\'\i}z, Shirley and others},
  type={{B.S.} thesis},
  year={2010},
  school={Universidad EAFIT}
}

@book{sanchez2007gestion,
  title={Gesti\'{o}n y Minimizaci\'{o}n de Residuos},
  author={S\'{a}nchez, M.F. and Castro, J.G.},
  isbn={9788496743342},
  url={https://books.google.es/books?id=uMdNfGpLUKcC},
  year={2007},
  publisher={Fundaci\'{o}n Confemetal}
}

@article{Emergencia2019,
	author={Alfonso, C and 
			Est\'{e}vez Est\'{e}vez, R and
			Lobo, J. M. and
			Lozano Di\'{e}guez, B. and
			Prieto, F. and
			Santamarta, J. and
			Gaerter, A.},
	year = 2016,
	month = {Diciembre},
	title={Emergencia clim\'{a}tica en {Espa\~{n}a}},
	organization = {Observatorio Sostenibilidad}
}
%	author={Carlos Alfonso and 
%			Ra\'{u}l Est\'{e}vez Est\'{e}vez and
%			Jorge M. Lobo and
%			Begoña Lozano Di\'{e}guez and
%			Fernando Prieto and
%			Jos\'{e} Santamarta and
%			\'{A}lvaro Gaerter},


@book{fonfria1989ingenieria,
  title={Ingenier\'{i}a ambiental: contaminaci\'{o}n y tratamientos},
  author={Fonfr\'{i}a, R.S. and Sans, R. and de Pablo Ribas, J.},
  isbn={9788426707420},
  series={Colecci\'{o}n productiva},
  url={https://books.google.es/books?id=kumplOJs6T0C},
  year={1989},
  publisher={Marcombo}
}

@Book{Karim2018,
    author = {Rezaul Karim},
    title = {TensorFlow: Powerful Predictive Analytics with TensorFlow},
    publisher = {Packt Publishing, Limited},
    year = {2018}
}

@Inbook{Wang2003,
    author={Wang, Sun-Chong},
    title={Artificial Neural Network},
    bookTitle={Interdisciplinary Computing in Java Programming},
    year={2003},
    publisher={Springer US},
    address={Boston, MA},
    pages={81--100},
    abstract={Inspired by the sophisticated functionality of human brains where hundreds of billions    of interconnected neurons process information in parallel, researchers have successfully tried demonstrating certain levels of intelligence on silicon. Examples include language translation and pattern recognition software. While simulation of human consciousness and emotion is still in the realm of science fiction, we, in this chapter, consider artificial neural networks as universal function approximators. Especially, we introduce neural networks which are suited for time series forecasts.},
    isbn={978-1-4615-0377-4},
    doi={10.1007/978-1-4615-0377-4_5},
    url={https://doi.org/10.1007/978-1-4615-0377-4_5}
}



@article{Dai_2020,
	doi = {10.1088/1742-6596/1651/1/012114},
	url = {https://doi.org/10.1088/1742-6596/1651/1/012114},
	year = {2020},
	month = {nov},
	publisher = {{IOP} Publishing},
	volume = {1651},
	pages = {012114},
	author = {Junyan Dai},
	title = {Real-time and accurate object detection on edge device with {TensorFlow} Lite},
	journal = {Journal of Physics: Conference Series},
	abstract = {Objection detection is of vital importance to many fields, such as autonomous driving, outdoor robotics, and computer vision. Existing approaches on object detection can hardly run on the resource-constrained edge devices. In order to mitigate this dilemma, we propose to apply TensorFlow Lite to convert Float32 neural network model to unit8 neural network with subtle or even no accuracy loss. Two advantages are here for conversion. First, it reduces the model size to a quarter so that it fits for devices with limited storage. Second, it achieves much faster inference time. I conduct an experiment on MSCOCO dataset. Experimental results show that our proposed method achieves mAP 72.1 and FPS 23 on edge device.}
}

@misc{tensorflow2015whitepaper,
title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
url={https://www.tensorflow.org/},
note={Software available from tensorflow.org},
author={
    Mart\'{\i}n~Abadi and
    Ashish~Agarwal and
    Paul~Barham and
    Eugene~Brevdo and
    Zhifeng~Chen and
    Craig~Citro and
    Greg~S.~Corrado and
    Andy~Davis and
    Jeffrey~Dean and
    Matthieu~Devin and
    Sanjay~Ghemawat and
    Ian~Goodfellow and
    Andrew~Harp and
    Geoffrey~Irving and
    Michael~Isard and
    Yangqing Jia and
    Rafal~Jozefowicz and
    Lukasz~Kaiser and
    Manjunath~Kudlur and
    Josh~Levenberg and
    Dandelion~Man\'{e} and
    Rajat~Monga and
    Sherry~Moore and
    Derek~Murray and
    Chris~Olah and
    Mike~Schuster and
    Jonathon~Shlens and
    Benoit~Steiner and
    Ilya~Sutskever and
    Kunal~Talwar and
    Paul~Tucker and
    Vincent~Vanhoucke and
    Vijay~Vasudevan and
    Fernanda~Vi\'{e}gas and
    Oriol~Vinyals and
    Pete~Warden and
    Martin~Wattenberg and
    Martin~Wicke and
    Yuan~Yu and
    Xiaoqiang~Zheng},
  year={2015}
}

@mastersthesis{Alsing2018,
   author = {Alsing, Oscar},
   institution = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   school = {KTH, School of Electrical Engineering and Computer Science (EECS)},
   title = {Mobile Object Detection using TensorFlow Lite and Transfer Learning},
   series = {TRITA-EECS-EX},
   number = {2018:535},
   keywords = {cnn, convolutional neural networks, transfer learning, mobile object detection},
   abstract = {With the advancement in deep learning in the past few years, we are able to create complex machine learning models for detecting objects in images, regardless of the characteristics of the objects to be detected. This development has enabled engineers to replace existing heuristics-based systems in favour of machine learning models with superior performance. In this report, we evaluate the viability of using deep learning models for object detection in real-time video feeds on mobile devices in terms of object detection performance and inference delay as either an end-to-end system or feature extractor for existing algorithms. Our results show a significant increase in object detection performance in comparison to existing algorithms with the use of transfer learning on neural networks adapted for mobile use. },
   year = {2018}
}

@misc{howard2017mobilenets,
      title={MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications}, 
      author={Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
      year={2017},
      eprint={1704.04861},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{iandola2016squeezenet,
      title={SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}, 
      author={Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
      year={2016},
      eprint={1602.07360},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{LiShuangfeng1839,
author = {Li Shuangfeng},
title = {TensorFlow Lite: On-Device Machine Learning Framework},
publisher = {Journal of Computer Research and Development},
year = {2020},
journal = {Journal of Computer Research and Development},
volume = {57},
number = {9},
eid = {1839},
numpages = {14},
pages = {1839},
keywords = {machine learning; on-device machine learning (ODML); TensorFlow; TensorFlow Lite; TFLite; mobile; IoT},
url = {https://crad.ict.ac.cn/EN/abstract/article_4251.shtml},
doi = {10.7544/issn1000-1239.2020.20200291}
}   

@article{merlin2020squeeze,
  title={Squeeze for Sneeze: Compact Neural Networks for Cold and Flu Recognition},
  author={Merlin Albes, Zhao Ren and Schuller, Bj{\"o}rn W and Cummins, Nicholas},
  year={2020}
}

@INPROCEEDINGS{7844626,  
	author={Paul, Rahul and Hawkins, 
			Samuel H. and Hall, 
			Lawrence O. and Goldgof, 
			Dmitry B. and 	
			Gillies, Robert J.},  
	booktitle={2016 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},   	
	title={Combining deep neural network and traditional image features to improve survival prediction accuracy for lung cancer patients from diagnostic CT},   
	year={2016},  
	pages={002570-002575},  
	doi={10.1109/SMC.2016.7844626},
	url = {https://ieeexplore.ieee.org/abstract/document/7844626}
}

@unpublished{Aitor2019Signos,
           month = {Julio},
           title = {Desarrollo de un sistema autom{\'a}tico de reconocimiento de lenguaje de signos},
          author = {Aitor Alc{\'a}zar Fern{\'a}ndez},
         address = {Madrid},
            year = {2019},
        keywords = {Personas con discapacidad; Redes neuronales; Reconocimiento de im{\'a}genes},
             url = {http://oa.upm.es/56626/},
        abstract = {Actualmente, las personas con discapacidades auditivas y del habla recurren al lenguaje de signos para comunicarse entre s{\'i}, pero es una actividad que {\'u}nicamente se puede realizar de forma presencial y entre personas que conozcan dicha lengua. Para poder establecer la comunicaci{\'o}n con el resto de las personas, es necesario recurrir a un intermediario o traductor, que haga las veces de emisor y receptor entre ambos. Esto resulta poco pr{\'a}ctico y, en la mayor{\'i}a de las ocasiones, costoso. Se pretende con este proyecto desarrollar un sistema capaz de traducir en tiempo real la detecci{\'o}n de signos aislados de la lengua de signos americana (American Sign Language - ASL). El software consiste en una inteligencia artificial entrenada para monitorizar los movimientos de las manos de la persona situada frente a la c{\'a}mara de un terminal m{\'o}vil, y mostrar por pantalla el signo traducido en ese momento sobre la imagen captada. Para ello, se han seguido dos l{\'i}neas de investigaci{\'o}n: con la primera, se ha desarrollado un traductor del alfabeto de la ASL recogiendo im{\'a}genes desde una c{\'a}mara IP en un terminal m{\'o}vil, procesando los datos y mostrando los resultados en el ordenador. La segunda l{\'i}nea de investigaci{\'o}n ha sido m{\'a}s ambiciosa, pues se ha conseguido traducir cuatro signos din{\'a}micos aislados, y desplegar el sistema creado en un terminal m{\'o}vil Android, el cual ejecuta una aplicaci{\'o}n aut{\'o}noma de traducci{\'o}n de estos signos en tiempo real. Gracias al desarrollo de este sistema, el grado de adaptaci{\'o}n para las personas con dichas dificultades comunicativas puede lograr un crecimiento de gran magnitud en distintos aspectos: de manera social, dando pie a una comunicaci{\'o}n m{\'a}s amplia y acercando la ASL a todos; cultural, educando a las personas que carecen de los conocimientos necesarios para comunicarse con ellos; y econ{\'o}mico, pues supone abaratar los costes relacionados con traductores personales y cursos formativos.}
}

@misc{benchmark2020comparison,
      title={Comparison and Benchmarking of AI Models and Frameworks on Mobile Devices}, 
      author={Chunjie Luo and 
      		  Xiwen He and 
      		  Jianfeng Zhan and 
      		  Lei Wang and 
      		  Wanling Gao and 
      		  Jiahui Dai},
      year={2020},
      eprint={2005.05085},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{pytorch2019,
      title={PyTorch: An Imperative Style, High-Performance Deep Learning Library}, 
      author={Adam Paszke and 
      		  Sam Gross and 
      		  Francisco Massa and 
      		  Adam Lerer and 
      		  James Bradbury and 
      		  Gregory Chanan and 
      		  Trevor Killeen and 
      		  Zeming Lin and 
      		  Natalia Gimelshein and 
      		  Luca Antiga and 
      		  Alban Desmaison and 
      		  Andreas Köpf and 
      		  Edward Yang and 
      		  Zach DeVito and 
      		  Martin Raison and 
      		  Alykhan Tejani and 
      		  Sasank Chilamkurthy and 
      		  Benoit Steiner and 
      		  Lu Fang and 
      		  Junjie Bai and 
      		  Soumith Chintala},
      year={2019},
      eprint={1912.01703},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@INPROCEEDINGS{unsupervised2013,
  author={Le, Quoc V. and 
  		  Aurelio Ranzato, Marc' and
  		  Monga, Rajat and
  		  Devin, Matthieu and
  		  Chan, Kai and
  		  Corrado, Greg S. and
  		  Dean, Jeff and
  		  Ng, Andrew Y.},
  booktitle={2013 IEEE International Conference on Acoustics, Speech and Signal Processing}, 
  title={Building high-level features using large scale unsupervised learning}, 
  year={2013},
  volume={},
  number={},
  pages={8595-8598},
  doi={10.1109/ICASSP.2013.6639343}
}
  
@book{warden2019tinyml,
  title={TinyML: Machine Learning with TensorFlow Lite on Arduino and Ultra-Low-Power Microcontrollers},
  author={Warden, P. and Situnayake, D.},
  isbn={9781492051992},
  url={https://books.google.es/books?id=tH3EDwAAQBAJ},
  year={2019},
  publisher={O'Reilly Media}
}

@InProceedings{mobilenev22018,
	author = {Sandler, Mark and 
		  Howard, Andrew and 
		  Zhu, Menglong and 
		  Zhmoginov, Andrey and 
		  Chen, Liang-Chieh},
	title = {MobileNetV2: Inverted Residuals and Linear Bottlenecks},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2018}
}

@misc{goodfellow2014generative,
      title={Generative Adversarial Networks}, 
      author={Ian J. Goodfellow and 
      		  Jean Pouget-Abadie and 
      		  Mehdi Mirza and 
      		  Bing Xu and 
      		  David Warde-Farley and 
      		  Sherjil Ozair and 
      		  Aaron Courville and 
      		  Yoshua Bengio},
      year={2014},
      eprint={1406.2661},
      archivePrefix={arXiv},
      primaryClass={stat.ML},
      url={https://arxiv.org/abs/1406.2661}
}

@InProceedings{synthia2016,
	author = {Ros, German and 
			  Sellart, Laura and 
			  Materzynska, Joanna and 
			  Vazquez, David and 
			  Lopez, Antonio M.},
	title = {The SYNTHIA Dataset: A Large Collection of Synthetic Images for Semantic Segmentation of Urban Scenes},
	booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
	month = {June},
	year = {2016},
	url={http://synthia-dataset.net/}
}

@inproceedings{industrialdetection2020,
  TITLE = {{CAD-based Learning for Egocentric Object Detection in Industrial Context}},
  AUTHOR = {Cohen, Julia and 
  		    Crispim-Junior, Carlos F. and 
  		    Grange-Faivre, C{\'e}line and 
  		    Tougne, Laure},
  URL = {https://hal.archives-ouvertes.fr/hal-02553622},
  BOOKTITLE = {{15th International Conference on Computer Vision Theory and Applications}},
  ADDRESS = {Valletta, Malta},
  PUBLISHER = {{SCITEPRESS - Science and Technology Publications}},
  VOLUME = {5},
  PAGES = {644-651},
  YEAR = {2020},
  MONTH = Feb,
  DOI = {10.5220/0008975506440651},
  KEYWORDS = {Object Detection ; Egocentric ; Database Generation},
  PDF = {https://hal.archives-ouvertes.fr/hal-02553622/file/VISAPP_camera-ready.pdf},
  HAL_ID = {hal-02553622},
  HAL_VERSION = {v1},
}

@inproceedings{lepetit2008,
   title = {Simultaneous Recognition and Homography Extraction of Local Patches with a Simple Linear Classifier},
   author = {Hinterstoisser, S. and 
   			 Benhimane, S. and 
   			 Lepetit, V. and 
   			 Fua, P. and 
   			 Navab, N.},
   year = {2008},
   pages = {10.1-10.10},
   booktitle = {Proceedings of the British Machine Vision Conference},
   publisher = {BMVA Press},
   editors = {Everingham, M. and Needham, C.},
   isbn = {1-901725-36-7},
   note = {doi:10.5244/C.22.10},
   url={http://www.bmva.org/bmvc/2008/papers/16.html}
}

@misc{synthdet2020,
    title={Training a performant object detection {ML} model on synthetic data using {U}nity {P}erception tools},
    author={You-Cyuan Jhang and 
    		Adam Palmar and 
    		Bowen Li and 
    		Saurav Dhakad and 
    		Sanjay Kumar Vishwakarma and 
    		Jonathan Hogins and 
    		Adam Crespi and 
    		Chris Kerr and 
    		Sharmila Chockalingam and 
    		Cesar Romero and 
    		Alex Thaman and 
    		Sujoy Ganguly},
    url = {https://blogs.unity3d.com/2020/09/17/training-a-performant-object-detection-ml-model-on-synthetic-data-using-unity-computer-vision-tools/},
    journal={Unity Technologies Blog},
    publisher={Unity Technologies},
    year={2020},
    month={Sep}
}

@misc{perception2021,
    title={Unity {P}erception Package},
    author={{Unity Technologies}},
    url = {https://github.com/Unity-Technologies/com.unity.perception},
    year={2020}
}

@article{amazongo2018,
  title={The amazon go concept: Implications, applications, and sustainability},
  author={Polacco, Alex and Backes, Kayla},
  journal={Journal of Business and Management},
  volume={24},
  number={1},
  pages={79--92},
  year={2018},
}

@article{lepetitdrones2014,
	author = {Rozantsev, Artem and 
			  Lepetit, Vincent and 
			  Fua, Pascal},
	year = {2014},
	month = {11},
	ages = {},
	title = {On Rendering Synthetic Images for Training an Object Detector},
	volume = {137},
	journal = {Computer Vision and Image Understanding},
	doi = {10.1016/j.cviu.2014.12.006},
	url={https://www.researchgate.net/publication/268987900_On_Rendering_Synthetic_Images_for_Training_an_Object_Detector}
}

@book{cyganek2013object,
  title={Object Detection and Recognition in Digital Images: Theory and Practice},
  author={Cyganek, B.},
  isbn={9781118618363},
  lccn={2012050754},
  url={https://ebookcentral.proquest.com/lib/universidadcomplutense-ebooks/detail.action?docID=1204058\#},
  year={2013},
  publisher={Wiley}
}

@Inbook{objectdetection2020,
	author={Amit, Yali and 
			Felzenszwalb, Pedro and 
			Girshick, Ross},
	title={Object Detection},
	bookTitle={Computer Vision: A Reference Guide},
	year={2020},
	publisher={Springer International Publishing},
	address={Cham},
	isbn={978-3-030-03243-2},
	doi={10.1007/978-3-030-03243-2_660-1},
	url={https://doi.org/10.1007/978-3-030-03243-2_660-1}
}

@book{amit20022d,
  title={2D Object Detection and Recognition: Models, Algorithms, and Networks},
  author={Amit, Y.},
  isbn={9780262011945},
  lccn={2002016508},
  series={Mit Press},
  url={https://books.google.es/books?id=3gJIX\_NmNG4C},
  year={2002},
  publisher={MIT Press}
}

@article{polacco2018amazon,
  title={The amazon go concept: Implications, applications, and sustainability},
  author={Polacco, Alex and Backes, Kayla},
  journal={Journal of Business and Management},
  volume={24},
  number={1},
  pages={79--92},
  year={2018},
  publisher={???}
}

@book{vocus2006,
  title={VOCUS: A visual attention system for object detection and goal-directed search},
  author={Frintrop, Simone},
  volume={3899},
  year={2006},
  publisher={Springer}
}

@book{michelucci2019advanced,
  title={Advanced applied deep learning: convolutional neural networks and object detection},
  author={Michelucci, Umberto},
  year={2019},
  publisher={Springer}
}

@book{jiang2019deep,
  title={Deep Learning in object detection and recognition},
  author={Jiang, Xiaoyue and 
  		  Hadid, Abdenour and 
  		  Pang, Yanwei and 
  		  Granger, Eric and 
  		  Feng, Xiaoyi},
  year={2019},
  publisher={Springer}
}

@article{matriculas2006,
  title={Reconocimiento autom{\'a}tico de matr{\'\i}culas},
  author={Parra Ramos, Carlos and Regajo Rodr{\'\i}guez, David },
  journal={Universidad Carlos III de Madrid},
  year={2006}
}
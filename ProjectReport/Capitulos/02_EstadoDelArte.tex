%---------------------------------------------------------------------
%
%                          Capítulo 2
%
%---------------------------------------------------------------------
\chapter{Estado del arte}
\label{cap2}



%-------------------------------------------------------------------
\section{Aplicaciones de reciclaje}
%-------------------------------------------------------------------
\label{cap2:sec:aplicaciones-reciclaje}
Con el modelo actual de sociedad, donde se ha incrementado la utilización de envases de un único uso, ha habido un aumento desmesurado de los residuos urbanos~\cite{sanchez2007gestion}%, fonfria1989ingenieria}; 
cuya recuperación y reutilización es importante para disminuir el impacto medioambiental que producen. Para llevarlo a cabo, es importante la separación de los residuos desde el origen, ya que permite que sean clasificados y almacenados de tal manera que se puedan disponer correctamente~\cite{shirley2010analisis}.
Para ello, se pide ayuda a la ciudadanía con el objetivo de fomentar la separación de residuos en el hogar.

Se tienen así diferentes tipos de residuos, que se depositan en contenedores distintos, identificados por colores. Para que tenga éxito, es necesario realizar la separación en el origen correctamente, ya que de no ser así los esfuerzos serían en vano.

Se hacen campañas muy diversas para concienciar a la población de la importancia de este proceso, además de enseñar a llevarlo a cabo. Pero no siempre es fácil saber en qué contenedor depositar ciertos residuos.
Para ayudar a la población estas campañas informativas reparten folletos o imanes para la nevera y, en última instancia, se puede recurrir a los puntos limpios de cada localidad. No obstante, con la presencia universal de teléfonos móviles en los hogares, las aplicaciones para ellos se han convertido en una vía informativa útil que está disponible en el momento en el que se necesita.

Cada país usa una gestión de recursos distinta, y por tanto las guías para los ciudadanos deben adaptarse a las idiosincrasias de cada sistema; debido a eso, las aplicaciones de ayuda están adaptadas a cada país. Puesto que abarcar todas las opciones es complejo este trabajo se enfoca al sistema utilizado en el territorio nacional.

En España, en aplicaciones de reciclaje que identifiquen objetos contamos con dos. La primera es ``AIRE: Asistente Inteligente de Reciclaje''\footnote{\url{https://www.ecoembes.com/proyectos-destacados/chatbot-aire/}} (figura~\ref{fig:apps:aire}), disponible tanto para iOS, Android y navegador, es una aplicación publicada por ecoembes, empresa encargada del reciclaje de los residuos de los contenedores amarillo y azul en España. Se trata de un asistente virtual con el que se tiene una conversación de chat, el usuario escribe el material o el objeto que desea reciclar y el \textit{bot} le responde explicando la forma idónea de desecharlo. Además del chat, esta aplicación también cuenta con la posibilidad de enviar imágenes y audios para la identificación del objeto. 

Otra es ``ReciclaYa''\footnote{\url{https://www.reciclaya.app/es/como-funciona}} (figura~\ref{fig:apps:reciclaya}), aplicación desarrollada por Carrefour. En este caso la identificación se lleva a cabo mediante el código de barras del ticket de la compra que se haya hecho. Según qué productos se hayan adquirido indica cómo reciclar cada uno sus envases. Esta funcionalidad está sólo disponible para algunas de las marcas principales, ya que son las propias empresas las que brindan esa información. Algunas de estas empresas sobre las que se disponen los datos son Carrefour, Coca Cola, Nestlé, Central Lechera Asturiana, Mahou San Miguel, PepsiCo, El Pozo o Pescanova, entre muchas otras.

Además de aplicaciones de identificación de residuos, también se encuentran numerosas aplicaciones enfocadas más a la ayuda y el aprendizaje sobre reciclaje. Algunos ejemplos son ``Residuos'' (figura~\ref{fig:apps:residuos}) de la Generalitat de Catalunya\footnote{\url{https://play.google.com/store/apps/details?id=cat.gencat.mobi.residus}} en colaboración con ecomenbes y ecovidirio. Esta aplicación cuenta con una base de datos de residuos con su respectivo contenedor adecuado y el proceso que sigue una vez es desechado en este. Cuenta con dos maneras de informar sobre cada desecho. La primera es por contenedores, se selecciona el contenedor respecto al que se quiere tener más información, sobre este sale un listado de todos los residuos disponibles en la base de datos reciclables en él, y finalmente se selecciona uno de ellos. La segunda manera es introducir en el buscador el residuo. En ambas opciones se explica el proceso que sufre este desecho desde el contenedor, su paso por la plantas de selección y reciclaje, y en qué se transforma finalmente. Además de informar sobre la forma adecuada de deshacerse de cada residuo, también cuenta con un buscador de puntos limpios a partir de la localización del dispositivo o mediante un buscador.

Otro ejemplo es ``Recicla y suma'' (figura~\ref{fig:apps:reciclaysuma}) de Pensumo\footnote{\url{https://reciclaysuma.com/}}. Es una herramienta pensada para incentivar el reciclaje animando al ciudadano a que se acostumbre a separar en casa los residuos que genera para luego acudir a los contenedores y reciclarlos. Pensumo es una \textit{start-up} que recompensa económicamente el reciclaje gracias a la colaboración de distintas empresas. El objetivo principal es generar el hábito en el ciudadano, para que, animado por el incentivo económico, acabe interiorizando la necesidad de reciclar y aprenda a depositar correctamente los residuos. Los usuarios sacan fotos en el momento que depositan los residuos en el contenedor correcto y reciben una pequeña cantidad de dinero por la acción.

Alejándose un poco del reciclaje como tal, encontramos ``The Planet  App''\footnote{\url{https://theplanetapp.com/}} por Clean Planet Ventures, SL. Es una aplicación de concienciación, aprendizaje y ayuda sobre la huella de carbono que genera cada uno. Permite al usuario calcular su huella de carbono y conocer las emisiones que genera separadas por categorías. La característica principal es la creación de un plan de sostenibilidad personalizado para adquirir hábitos y realizar acciones que disminuyan las emisiones que genera cada uno. Además, se pueden comparar las emisiones con las de distintos grupos poblacionales o las de otros usuarios.

En el lado internacional existen muchas más aplicaciones, como ``My Little Plastic Footprint''\footnote{\url{https://mylittleplasticfootprint.org/}}, de Plastic Soup Foundation. Esta es muy similar a la aplicación anterior, pero en vez de ser respecto a la huella de carbono es sobre el plástico que genera el usuario. En este caso, la aplicación indica el ``Índice de Masa Plástica'' (PMI por sus siglas en inglés). El concepto hace un símil con el índice de masa corporal, pero refiriéndose al consumo de plástico del usuario. Una vez calculado, comienza la denominada ``dieta de plástico'', que consiste en ir adquiriendo como hábito alternativas al plástico que se utiliza normalmente. A medida que se van incorporando los consejos de la aplicación al perfil del usuario, el PMI de este se irá reduciendo.

``Grow Recycling''\footnote{\url{https://www.groplay.com/apps/grow-recycling/}}, de Gro Play Digital, es un juego educativo para niños utilizado en colegios y guarderías en Estados Unidos y Europa para impartir educación sobre la sostenibilidad. El juego consiste en alimentar a distintos cubos de basura con los residuos correspondientes para que niños y niñas puedan aprender a cuidar del planeta.
Otra aplicación educativa de reciclaje es ``Recycle Coach''\footnote{\url{https://recyclecoach.com/}}, de Municipal Media Inc., con ella se puede aprender sobre el proceso de reciclaje, los diferentes materiales y el proceso de depósito y recogida de residuos en tu zona. Además, cuenta con \textit{tests}, artículos y actividades para aprender apropiadamente sobre el desechado de residuos.  

Como se ha descrito en la introducción, el objetivo del TFG es hacer una aplicación de este tipo pero que indique cómo reciclar un objeto a partir de una imagen tomada con el móvil. Para eso es necesario realizar una identificación de objetos, sobre lo que se describen a continuación varias aplicaciones de ejemplo.
\begin{figure}
	\centering
	\subfloat[AIRE]{
		{{\includegraphics[width=0.3\textwidth]{Imagenes/AIRE}}}
		\label{fig:apps:aire}}
	\qquad
	\subfloat[ReciclaYa. Imagen de la página web oficial.]{
		{{\includegraphics[width=0.34\textwidth]{Imagenes/reciclaYa}}}
		\label{fig:apps:reciclaya}}
	\qquad
	\subfloat[Residuos]{
		{{\includegraphics[width=0.3\textwidth]{Imagenes/Residus}}}
		\label{fig:apps:residuos}}
	\qquad
	\subfloat[Recicla Y Suma. Imagen de la página web oficial.]{
		{{\includegraphics[width=0.3\textwidth]{Imagenes/reciclaYSumaIMG}}}
		\label{fig:apps:reciclaysuma}}
	\caption{Aplicaciones de reciclaje}
    \label{fig:latas}
\end{figure}

%-------------------------------------------------------------------
\section{Identificación de objetos e imágenes}
%-------------------------------------------------------------------
\label{cap2:sec:identificacion}

La detección e identificación de objetos es un campo de la visión artificial y el procesamiento de imágenes. El objetivo de la visión computacional es desarrollar algoritmos que reciban una imagen de entrada y produzcan una interpretación describiendo los objetos presentes, en qué posición y la relación espacial tridimensional entre ellos. A pesar de que actualmente ya es posible detectar y reconocer objetos en conjuntos de miles de imágenes complejas, todavía no se cuenta con un paradigma aceptado y dominante con el que la mayoría de investigadores trabajen~\cite{amit20022d}.

La detección, seguimiento y  reconocimiento de objetos en imágenes es uno de los problemas claves en visión computacional~\cite{cyganek2013object}. Normalmente, en cada imagen sólo aparece una pequeña cantidad de los objetos posibles, pero estos pueden encontrarse en una gran cantidad de posiciones y escalas que se deben tener en cuenta~\cite{objectdetection2020}.

Esto es algo utilizado en diversos ámbitos, desde objetos, personas y caras, hasta campos mucho más específicos. Un ejemplo es VOCUS (Visual Object detection with a CompUtational attention System)~\cite{vocus2006}, un sistema capaz de seleccionar automáticamente secciones de interés en imágenes y detectar objetos específicos. Cuenta con dos modos de trabajo, un primer modo de exploración en el que no se especifica un objetivo y en el que se buscan zonas de interés. Son consideradas zonas de interés aquellas en las que haya grandes contrastes o características únicas (por ejemplo una oveja negra en un rebaño de ovejas blancas). El segundo modo es de búsqueda con un objetivo definido, en este modo se utiliza información previamente aprendida sobre el objetivo para seleccionar las computaciones más destacadas respecto a ello.

Otro ejemplo es el reconocimiento de matrículas de los coches presentes en una imagen~\cite{matriculas2006}. En este caso se presenta una doble identificación, ya que primero debe localizarse la matrícula en la imagen y posteriormente sobre esta se tiene que llevar a cabo la segmentación e identificación de los caracteres que la componen.

En el apartado~\ref{cap2:sec:generacion} se hablará en más profundidad sobre varios proyectos de generación de \textit{datasets} sintéticos. Todos ellos, además, tienen también como objetivo la identificación de objetos en imágenes.

Destacamos además, algunos proyectos semejantes al que se presenta en este trabajo de fin de grado, ya que cuentan tanto con parte de identificación de objetos, como de generación de \textit{dataset}. En este punto del capítulo se hablará de lo primero, la identificación; en cambio la generación de imágenes se tratará más en profundidad en la sección~\ref{cap2:sec:generacion}.

SynthDet~\cite{synthdet2020} es un proyecto cuyo fin es identificar los distintos productos contenidos en carritos de la compra con el objetivo de facturar automáticamente las adquisiciones de los clientes en supermercados. Está basado en Amazon~Go~\cite{amazongo2018}, supermercado de la empresa Amazon, ubicado en Seattle (Estados Unidos). 
El modelo de Amazon~Go se basa en un sistema de cámaras y sensores distribuidos por el establecimiento que analizan los movimientos de los clientes. Estos, además de obtener la información necesaria para realizar los cobros, también extraen información sobre las pautas de comportamiento de los consumidores~\cite{polacco2018amazon}. SynthDet propone realizar la misma tarea de identificación y facturación de productos, pero entrenando el modelo a partir de imágenes sintéticas.

Otros proyectos relacionados son la detección de drones~\cite{lepetitdrones2014} y la identificación de piezas industriales~\cite{industrialdetection2020}, que cuentan con un trasfondo similar de identificar objetos en entornos reales. 

Pero la inclusión y el desarrollo de la detección y la identificación de objetos no se limita al entorno de la investigación y a usos específicos; sino que en la vida cotidiana también se percibe un crecimiento de este ámbito. Actualmente el uso de la detección e identificación de objetos se está expandiendo por más aplicaciones, una de las más conocidas y extendidas es Google~Lens\footnote{\url{https://lens.google/intl/es-419/}}, la cual tiene diversas funcionalidades dentro del mundo de la detección de objetos. Esta aplicación es una de las más completas en este dominio, a partir de una imagen o de la cámara del dispositivo, escanea y traduce textos; identifica objetos y busca en Google otros similares; reconoce lugares y edificios, ofreciendo información sobre ellos; detecta animales y plantas; y registra operaciones matemáticas sobre las que ofrece explicaciones y resultados de la web. 

Otra aplicación de Google con identificación de objetos es Google~Fotos\footnote{\url{https://www.google.com/intl/es/photos/about/}}, una plataforma de intercambio y almacenamiento de fotografías y vídeos. Puede utilizarse en conjunto con Google~Lens para tener todas las funcionalidades mencionadas anteriormente sobre las imágenes almacenadas en la aplicación, pero además Google~Fotos cuenta con su propia funcionalidad de identificación de texto, objetos y personas. En la aplicación pueden realizarse búsquedas que devuelven una selección de imágenes y vídeos en los que aparece la persona, objeto o texto buscado, además de funcionar con posturas y acciones.

Otras aplicaciones similares, aunque algo más rústicas, son las recogidas en el paquete de  Microsoft~Office. En este caso la identificación se presenta como una funcionalidad de accesibilidad para personas con discapacidad visual. Se trata del texto alternativo, disponible para imágenes, formas, vídeos, gráficos y tablas, entre otros. En algunas de sus aplicaciones Microsoft va un paso más allá y genera el texto alternativo de las imágenes automáticamente, identificando personas, objetos y situaciones.



%-------------------------------------------------------------------
\section{Redes neuronales}
%-------------------------------------------------------------------
\label{cap2:sec:redes-neuronales}

Todos los sistemas mencionados en el apartado anterior (\ref{cap2:sec:identificacion}) utilizan redes neuronales por debajo.
Las redes neuronales artificiales son una técnica de clasificación del aprendizaje automático, disciplina de la Inteligencia Artificial (IA) cuyo objetivo es la creación de mecanismos capaces de aprender de forma autónoma.
Estas surgen inspiradas por la funcionalidad sofisticada del cerebro humano, donde miles de millones de neuronas se encuentran interconectadas y procesan información de manera paralela. Tratan de emular el comportamiento del cerebro humano caracterizado por el aprendizaje a través de la experiencia y la extracción de conocimiento a partir de un conjunto de datos~\cite{lopez2008redes}. Además, simulan las características básicas de las redes neuronales biológicas; el procesamiento paralelo, la memoria distribuida y adaptabilidad. Esto permite a las redes artificiales aprender y generalizar a partir de un conjunto de datos de relación matemática desconocida~\cite{rnafundamentos1995}.
De esta forma, adquieren, almacenan y utilizan conocimientos basados en la experiencia en lugar de ser programados de manera explícita~\cite{zurada1992introduction}.

Una red neuronal artificial consta de una capa de entrada de neuronas, una o varias capas ocultas y una capa final de salida. En la figura~\ref{fig:RN} 
se muestra la estructura habitual de una red neuronal artificial.

\figura{EsquemaRedNeuronal.pdf}{width=1\textwidth}{fig:RN}{Estructura de una red neuronal artificial.}

Las neuronas reciben varias entradas y las combinan, le aplican la función de activación y el resultado es transmitido a otra neurona. La función de activación en redes neuronales devuelve una salida que es generada por una o varias entradas. Cada capa de la red cuenta con una función de activación. Las neuronas están conectadas entre sí mediante líneas y a cada una de estas conexiones se asocia con un valor numérico llamado peso~\cite{Wang2003, salas2004redes, basogain2008redes}.
Durante el aprendizaje de la red se modifica el valor de los pesos asociados a las neuronas con el fin de que generar una salida a partir de unos datos de entrada. Se considera que el aprendizaje ha terminado cuando los valores de los pesos permanecen estables.

Aunque existen muchas definiciones para las redes neuronales, una de las más extendidas establece que una red neuronal artificial se define como un grafo dirigido, donde los nodos representan las neuronas y las aristas la sinapsis. Aquellos nodos que no cuentan con conexiones entrantes son consideradas las neuronas de entrada, y los que no tiene conexiones salientes las de salida. El resto de neuronas se consideran capas ocultas, las cuales cuentan con conexiones de entrada y de salida~\cite{lopez2008redes, annealing2004, rnafundamentos1995, muller1995neural}.


Algunos autores consideran que las redes neuronales artificiales se inspiraron en el trabajo de Ramón y Cajal quien, en 1888, demostró que el sistema nervioso está compuesto por una red de células individuales conectadas entre sí, las neuronas~\cite{lopez2008redes}. Otros nombran a Alan Turing como pionero al estudiar el cerebro como una forma de ver el mundo de la computación. 
Independientemente, en todos los casos se toma a Warren McCulloch (neurobiólogo) y Walter Pitts (estadístico) como los primeros teóricos que concibieron fundamentos de la computación neuronal en el artículo \textit{``A logical calculus of Ideas Imminent in Nervous Activity''} en 1943~\cite{firstrna1943}. 
%Posteriormente, en 1956, tuvo lugar el congreso de Dartmouth, comúnmente considerado el nacimiento de la inteligencia artificial. 
Posteriormente, en 1958, Frank Rosenblatt comenzó el desarrollo de lo que terminaría conociéndose como perceptrón~\cite{rosenblatt1958perceptron}.

El perceptron es un sistema clasificador de patrones capaz de reconocer patrones similares a los del entrenamiento pero que no había visto antes. Sin embargo, contaba con ciertas limitaciones, la más importante fue que no era capaz de resolver clasificar clases no separables linealmente, como por ejemplo la función lógica OR~exclusiva\footnote{XOR u OR exclusiva es una puerta lógica cuya salida es verdadera si una, y sólo una, de las entradas es verdadera. Si ambas son falsas o ambas son verdaderas la salida es falsa.}. Esto fue demostrado matemáticamente en los años 60 por Minsky y Papert~\cite{minskypapert2017perceptrons}, lo que desencadenó un fuerte desinterés en la computación neuronal.

%Antes de esto se desarrollaron algunos modelos más, dos de ellos fueron "Adeline" (\textit{ADAptative LINear Elements}) y "Madeline"\footnote{"Madeline" fue una segunda versión que contaba con dos capas}, por Bernard Widrow, que se utilizaron principalmente, en el desarrollo de filtros adaptativos para eliminar el eco de las líneas telefónicas.

No fue hasta principios de los años 80 cuando se consiguió devolver el interés en este campo con el desarrollo de una red recurrente por parte de John Hopfield~\cite{Hopfield2554} y el redescubrimiento de David E. Rumelhart, Geoffrey E. Hinton y Ronald J. Willieams~\cite{rumelhart1986learning} del algoritmo de aprendizaje de propagación hacia atrás (\textit{backpropagation}) planteado por Paul Werbos en 1974~\cite{basogain2008redes, larranaga1997tema, matich2001conceptos, lucas2018Hopfield}.

Existen dos tipos de redes neuronales principales, las redes convolucionales y las recurrentes. Las primeras se desarrollaron para el reconocimiento de imágenes y son útiles para distinguir elementos esenciales en una entrada de la red compleja~\cite{movcorporalespavon2020}. Una particularidad de estas redes es la operación de convolución\footnote{Una convolución es un operador matemático que transforma dos funciones \textit{f} y \textit{g} en una tercera que representa la magnitud en la que se superponen \textit{f} y una versión trasladada e invertida de \textit{g}.} que se realiza en las primeras capas utilizándose como filtro, esto permite que tenga muchas aplicaciones en el tratamiento de imágenes~\cite{pacheco2017identificacion}. 
Por otro lado, las redes neuronales recurrentes son aquellas en las que la salida de una neurona vuelve en forma de entrada, por lo que puede haber ciclos en las conexiones entre las neuronas de cada capa. Cuentan con la peculiaridad de que no sólo aprenden de los datos sino también de secuencias de estos. Todo esto las convierte en buenas candidatas para trabajar con datos con dependencias estructurales en una dimensión, como el texto, o el audio~\cite{movcorporalespavon2020, guridi2017modelos}.

También se lleva a cabo una distinción en las redes neuronales según el paradigma de aprendizaje que siguen, existen tres tipos principales, las redes neuronales supervisadas, las no supervisadas y las de aprendizaje por refuerzo. Las redes neuronales supervisadas trabajan con datos etiquetados y se caracterizan por la presencia de un agente externo que controla el entrenamiento denominado supervisor. Este determina la respuesta que debería generar la red a partir de una entrada determinada y controla la salida de la red. En caso de que el resultado no coincida con el deseado se modifican los pesos de las conexiones con el fin de conseguir una salida aproximada a la esperada. 
En cambio, las redes con aprendizaje no supervisado no requieren influencia externa para ajustar los pesos de las conexiones entre sus neuronas. La red recibe datos sin etiquetar, es decir, no existen datos de salida correspondientes a una determinada entrada. En este modelo se agrupan los datos según sus propiedades y patrones, su objetivo es encontrar una estructura o configuración en los datos.
Por último, el aprendizaje por refuerzo se basa en mejorar los resultados de los modelos mediante retroalimentación que recibe del entorno según la salida seleccionada. El \textit{feedback} que recibe indica con qué grado de satisfacción cumple la salida, conocida como acción, con el objetivo~\cite{matich2001conceptos, salas2004redes, simeone2018machinelearning}. 


El concepto de red neuronal deja abierta la decisión de su estructura: cuántas capas ocultas poner, de qué tamaño poner cada una, etcétera. Con el tiempo se han ido descubriendo estructuras de redes que funcionan bien para dominios concretos, por lo que se han utilizado una y otra vez y las distintas librerías para el uso de redes neuronales las incorporan entre sus opciones predefinidas.
Algunas de las Redes Neuronales más expandidas actualmente son AlexNet, VGGNet, MobileNet e GoogLeNet.

AlexNet~\cite{krizhevsky2012imagenet} es una red ampliamente utilizada que se dio a conocer en la competición de ImageNet~\cite{russakovsky2015imagenet}, donde consiguió el primer puesto con una tasa de error del 15.3\% (2012). Fue la primera red neuronal en utilizar ReLu\footnote{ReLu transforma los valores de entrada anulando los negativos y manteniendo los positivos.} como función de activación\footnote{} en vez de la función sigmoide\footnote{La función sigmoide transforma los valores de entrada a una escala entre 0 y 1.}. Este cambio mejoró notablemente la velocidad de entrenamiento de las redes de aprendizaje profundo~\cite{cortina2020automata, iandola2016squeezenet, comparinalexnetvgg2016}.

La segunda red destacada es VGGNet. Esta también saltó a la fama gracias a ImageNet en 2014. La diferencia más destacable con AlexNet es la gran cantidad de capas convolucionales que tiene. 
Además de una arquitectura más profunda destacó también por su simplicidad~\cite{simonyan2014vgg,comparinalexnetvgg2016, moreno2020analisis}.

GoogLeNet, también conocida como InceptionNet, fue desarrollada por Google, siendo de las primeras redes que no se basó en añadir más capas convolucionales para mejorar la red, sino que cambió la estructura de estas usando filtros de varios tamaños. El objetivo era tener filtros de diferentes tamaños para un mismo objeto. Esto provocó que la red fuera más ``ancha'' en vez de más profunda~\cite{inceptionnet2015}.

La última red es MobileNet, esta también fue desarrollada por Google. Surgió con la intención de adaptar GoogLeNet a dispositivos móviles. Su objetivo fue reducir el número de cálculos y parámetros pero manteniendo unos resultados similares~\cite{mobilenev22018, howard2017mobilenets}. 



%-------------------------------------------------------------------
\section{TensorFlow y TensorFlow Lite}
%-------------------------------------------------------------------
\label{cap2:sec:tensorflow}

En 2011 el equipo de investigación encargado de la inteligencia artificial de aprendizaje profundo de Google, Google~Brain, comenzó a investigar el uso de redes neuronales a gran escala para utilizarlo en los productos de la empresa. Como resultado desarrollaron DistBelief, un sistema escalable de entrenamiento e inferencia utilizado para GoogleNet~\cite{inceptionnet2015}. 
A partir de la experiencia obtenida en el desarrollo de DistBelief, y con un entendimiento más completo de las necesidades y requisitos necesarios para generar un sistema mejor, desarrollaron TensorFlow\footnote{\url{https://www.tensorflow.org/}}. 

Este es un entorno de trabajo de código abierto de aprendizaje automático que utiliza grafos de flujo de datos.
En estos grafos los nodos simbolizan las operaciones matemáticas, tales como sumas, multiplicaciones, factorización de matrices, y demás; mientras que los bordes representan los conjuntos de datos multidimensionales (tensores)~\cite{Karim2018}. 

TensorFlow puede ejecutarse en una gran variedad de plataformas diferentes, desde máquinas sencillas de una o varias GPUs, como los dispositivos móviles, hasta sistemas a gran escala de cientos de máquinas especializadas que cuentan con miles de GPUs. 
Su API y sus implementaciones de referencia fueron lanzadas en noviembre de 2015 como un paquete de código abierto bajo una licencia de Apache~2.0~\cite{tensorflow2015whitepaper, alberto2017modelopredictivotf, zamorano2019comparacion}.

%Como se ha comentado, TensorFlow fue desarrollado para ser ejecutado en sistemas muy diversos, incluidos dispositivos móviles. Este fue llamado TensorFlow~Mobile y permitió a los desarrolladores para móvil crear aplicaciones interactivas sin los retrasos que generaban los cálculos computacionales de aprendizaje automático. 

%A pesar de las optimizaciones de TensorFlow~Mobile para mejorar la actuación de los modelos y que el \textit{hardware} mínimo requerido era bastante accesible, seguía existiendo cuello de botella en la velocidad de cálculo computacional, debido a la baja latencia de los dispositivos móviles. %Por ejemplo, un dispositivo móvil cuyo \textit{hardware} era capaz de ejecutar 10~GFLOPS\footnote{\textit{Giga floating point operations per second}, proveniente de FLOPS, operaciones de coma flotante por segundo. } estaba limitado a ejecutar un modelo de 5~GFLOPS  a 2~FPS\footnote{\textit{frames} por segundo, del inglés \textit{frames per second}.}, lo que provocaba que las aplicaciones no funcionaran como era esperado \cite{Alsing2018}.

%TensorFlow~Lite es la evolución de TensorFlow~Mobile, algunas de las optimizaciones que incluye son el uso de \textit{frameworks} como la API de redes neuronales de Android y redes neuronales optimizadas para móvil como MobileNets \citep*{howard2017mobilenets} y SqueezeNet\citep*{iandola2016squeezenet}.

Para utilizar modelos de TensoFlow en dispositivos móviles, microcontroladores, sistemas embebidos o
relacionados con IoT (Internet of Things), Google desarrolló la librería de TensorFlow~Lite. Esta permite la optimización de los modelos para reducir su latencia y tamaño~\cite{morant2021sistemabajocoste}. Su entrenamiento se lleva a cabo en  una computadora, cuyo resultado se traslada posteriormente al dispositivo sin necesidad de utilizar un servidor. Para su uso, principalmente se utiliza la arquitectura MobileNet~\cite{mobilenev22018}, la cual está diseñada y optimizada para ser ejecutada en móviles, y sirve para la  detección y clasificación de objetos, detección de caras y reconocimiento de lugares en imágenes, aunque TensorFlow Lite también acepta el uso de SqueezeNet~\citep*{iandola2016squeezenet}, otra arquitectura optimizada para dispositivos móviles; e InceptionNet~\cite{inceptionnet2015}.

Como resultado del entrenamiento se generan dos archivos en el ordenador. El primero contiene las etiquetas para la clasificación, se trata de un archivo de texto plano con una lista de todos los objetos detectables por la red. El segundo, con extensión \textit{.tflite}, es el modelo entrenado de TensorFlow~Lite. Ambos archivos deben importarse en la aplicación móvil para su uso, la cual pude ser para Android, iOS o Raspberry. Estas deben estar desarrolladas en Java; Swift u Objective-C; y Python, respectivamente, ya que son los lenguajes para los que está disponible la API.


%-------------------------------------------------------------------
\section{Generación sintética de imágenes}
%-------------------------------------------------------------------
\label{cap2:sec:generacion}
Un problema del entrenamiento de redes neuronales es que se requieren muchos datos, y en caso de que la red esté enfocada a la identificación de objetos estos datos de entrenamiento deben de ser imágenes etiquetadas. Para facilitar la obtención de los \textit{dataset} en este trabajo de fin de grado se plantea la posibilidad de utilizar imágenes sintéticas.

Actualmente hay un contacto continuo con los gráficos generados informáticamente. Desde el desarrollo de videojuegos hasta el diseño de un reactor nuclear se apoyan en la informática gráfica. Esto abarca dos grandes campos de aplicación. Por un lado se aplica en el proceso de reconstruir un modelo 2D o 3D a partir de una imagen, esto es denominado procesamiento de la imagen. El proceso contrario es la síntesis de la imagen, consiste en la construcción sintética de imágenes a partir de modelos de dos o tres dimensiones. Dichos modelos pueden haber sido producidos por métodos artificiales o recogidos del mundo real~\cite{lopez1999ig}.

Históricamente el proceso requería mucho tiempo si se quería calidad fotorrealista, pero actualmente se pueden conseguir buenos resultados en tiempo real. Aun así, existen principalmente dos aproximaciones. La primera es usar herramientas de modelado con las que se crean los objetos en 3D y se ven representados, y la segunda es usar esos modelos para mostrarlos desde diferentes puntos en tiempo real, algo que hoy habitualmente significa usar motores de videojuegos.


SYNTHIA~\cite{synthia2016} es un \textit{dataset} de imágenes fotorrealistas generadas a partir de frames obtenidos de la renderización de un mundo virtual formado a partir de modelos tridimensionales. Estas imágenes además van acompañadas de anotaciones semánticas a nivel de \textit{pixel} que etiquetan los distintos objetos presentes en la escena, distinguiendo hasta 13 clases distintas. Este \textit{dataset} está orientado al entrenamiento de coches autónomos, sistemas de conducción asistida y proyectos relacionados, como complemento para diferentes \textit{datasets} reales (Camvid, KITTI, U-LabelMe, CBCL).

Otro ejemplo similar, es la generación de imágenes efectivas para el entrenamiento de detección de objetos partiendo de un conjunto pequeño de imágenes reales y el modelo tridimensional del objeto a identificar~\cite{lepetitdrones2014}. Los parámetros pueden reutilizarse para generar un número ilimitado de imágenes de entrenamiento del objeto de interés en poses arbitrarias. Por cada imagen real se computan cinco parámetros de la pose, tres de orientación y dos de traslación que permite colocar el modelo 3D en la posición deseada. Una vez se obtiene la imagen, para hacerla lo más similar a la imagen real, pasa por un postprocesamiento que involucra agregar desenfoque, para simular la lejanía y el movimiento del objeto; ruido, que imita el ruido que añade la cámara al tomar la fotografía; y propiedades del material del objeto. Esto permite que las imágenes generadas sintéticamente sean más similares a las reales, obteniendo un \textit{dataset} sintético muy similar a uno real.

Un proyecto basado en el anterior, es la detección de objetos en contextos industriales~\cite{industrialdetection2020}. En este proyecto se parte del modelo renderizado de una pieza utilizada en el entorno industrial con el que se genera un \textit{dataset}. Como en el caso anterior, para añadir más diversidad e identificar las piezas en un mayor número de situaciones, las imágenes se generan con diferentes fondos creados a partir de una selección de imágenes de localizaciones reales. Posteriormente, además, se altera la iluminación y se añaden sombras de distintas formas e intensidades creando imágenes desenfocadas o en movimiento. 

Perception~\cite{perception2021} es un paquete de Unity en desarrollo que proporciona herramientas para generar \textit{datasets} sintéticos a gran escala. Está planteado para tareas de aprendizaje automático, tales como detección de objetos, segmentación semántica y más. Este \textit{dataset} está formado por \textit{frames} capturados por sensores simulados, y que posteriormente se utilizan para el entrenamiento y la validación del modelo. Perception, además de permitir al usuario que produzca sus propios datos para la tarea que requiera, ofrece una cantidad de etiquetas comunes ya generadas para facilitar la creación de datos sintéticos. Además de la generación de \textit{datasets} sintéticos incluye herramientas para generar \textit{keypoints}, poses y animaciones aleatorias. Este paquete puede utilizarse para diversidad de proyectos, desde simulación de coches autónomos o \textit{smart cities}\footnote{\url{https://github.com/Unity-Technologies/Unity-Simulation-Smart-Camera-Outdoor}}, pasando por demostraciones de recoger y colocar objetos mediante un brazo robótico\footnote{\url{https://github.com/Unity-Technologies/Robotics-Object-Pose-Estimation}}, hasta detención  de objetos utilizando únicamente imágenes sintéticas para el entrenamiento.

Esto último hace referencia al proyecto SynthDet~\cite{synthdet2020}, ya mencionado anteriormente en la sección~\ref{cap2:sec:identificacion}. En este caso se utiliza Perception para crear el \textit{dataset} utilizado en el entrenamiento de la red neuronal. Generan imágenes de productos habituales de supermercados con el fin de estudiar la viabilidad de los supermercado sin cajas registradoras. Este objetivo se basa en el supermercado Amazon~Go~\cite{amazongo2018}, creado por Amazon en 2017.



%-------------------------------------------------------------------
\section{Unity}
%-------------------------------------------------------------------
\label{cap3:sec:unity}

Unity es una herramienta de creación de videojuegos desarrollada por Unity Technologies. Es ampliamente utilizada dentro de este ámbito como fuera de él debido a la cantidad de funcionalidades que ofrece de manera intuitiva y sencilla. Otros campos en los que se utiliza son la realización de contenido cinematográfico; transporte y producción, e incluso en arquitectura, ingeniería y construcción. Y permite el desarrollo de juegos y aplicaciones para un gran abanico de plataformas; desde PC, Mac y Linux, pasando por Android e iOS, hasta consolas de videojuegos como PlayStation~4, Xbox~One, Nintendo~Switch o Google~Stadia. 

La creación de contenido se realiza mediante el editor visual, que forma la interfaz, y programación vía \textit{scripting}.
Uno de los puntos a favor de utilizar motores de videojuegos es que permiten a los usuarios centrarse en el desarrollo de su aplicación sin necesidad de llevar a cabo partes más complejas, como la simulación de físicas o el renderizado, ya que es el motor quien se encarga de ello.
Unity utiliza una arquitectura basada en componentes. El motor proporciona unos propios (Transform, RidigBody, etc.) y permite que los desarrolladores creen los suyos utilizando C\#. El ciclo de vida de los componentes está definido por el motor, de manera que durante la ejecución de la aplicación, mediante la clase base \texttt{MonoBehaviour}\footnote{\url{https://docs.unity3d.com/ScriptReference/MonoBehaviour.html}}, se va llamando a métodos específicos para notificar el avance del juego y darles la oportunidad de actuar. Se tiene así funciones como el \texttt{Start()}\footnote{\url{https://docs.unity3d.com/ScriptReference/MonoBehaviour.Start.html}}, método que se llama en el frame que se habilita el \textit{script}, o el \texttt{Update()}\footnote{\url{https://docs.unity3d.com/ScriptReference/MonoBehaviour.Update.html}}, que se llama en todos los frames.

%Unity permite la carga de modelos tridimensionales externos así como los modelos geométricos básicos ya presentes en la herramienta. A estos se les puede añadir todos los componentes necesarios para darles una funcionalidad específica en la aplicación. 


%\todo{hablar de prefabs,Game Manager}	


%-------------------------------------------------------------------
%\section*{\NotasBibliograficas}
%-------------------------------------------------------------------
%\TocNotasBibliograficas

%Citamos algo para que aparezca en la bibliografía\ldots
%\citep{ldesc2e}

%\medskip

%Y también ponemos el acrónimo \ac{CVS} para que no cruja.

%Ten en cuenta que si no quieres acrónimos (o no quieres que te falle la compilación en ``release'' mientras no tengas ninguno) basta con que no definas la constante \verb+\acronimosEnRelease+ (en \texttt{config.tex}).


%-------------------------------------------------------------------
%\section*{\ProximoCapitulo}
%-------------------------------------------------------------------
%\TocProximoCapitulo
